{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "from datetime import datetime,timedelta\n",
    "from urllib.request import urlopen\n",
    "import sqlalchemy \n",
    "import pymysql\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MoneyTrend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6번째 페이지에서 누락된 값 발생\n",
      "누락된 데이터를 제거합니다\n",
      "15번째 페이지에서 누락된 값 발생\n",
      "누락된 데이터를 제거합니다\n",
      "23번째 페이지에서 누락된 값 발생\n",
      "누락된 데이터를 제거합니다\n",
      "82번째 페이지에서 누락된 값 발생\n",
      "누락된 데이터를 제거합니다\n",
      "146번째 페이지에서 누락된 값 발생\n",
      "누락된 데이터를 제거합니다\n",
      "203번째 페이지에서 누락된 값 발생\n",
      "누락된 데이터를 제거합니다\n",
      "205번째 페이지에서 누락된 값 발생\n",
      "누락된 데이터를 제거합니다\n",
      "205번째 페이지에서 누락된 값 발생\n",
      "누락된 데이터를 제거합니다\n",
      "209번째 페이지에서 누락된 값 발생\n",
      "누락된 데이터를 제거합니다\n",
      "212번째 페이지에서 누락된 값 발생\n",
      "누락된 데이터를 제거합니다\n",
      "234번째 페이지 크롤링 완료\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (4650) into shape (4651)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-833a6fe9ef65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m \u001b[0mget_money_trend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-833a6fe9ef65>\u001b[0m in \u001b[0;36mget_money_trend\u001b[1;34m()\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;31m#print(len(dictionary['채권형 펀드']))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'번째 페이지 크롤링 완료'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdate_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\kkang\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\kkang\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    281\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         ]\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\kkang\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\kkang\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_arrays\u001b[1;34m(arrays, names, axes)\u001b[0m\n\u001b[0;32m   1695\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmgr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1696\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1697\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mconstruction_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1699\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\kkang\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_arrays\u001b[1;34m(arrays, names, axes)\u001b[0m\n\u001b[0;32m   1690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1692\u001b[1;33m         \u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mform_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1693\u001b[0m         \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m         \u001b[0mmgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\kkang\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mform_blocks\u001b[1;34m(arrays, names, axes)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1780\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ObjectBlock\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1781\u001b[1;33m         \u001b[0mobject_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_simple_blockify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitems_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ObjectBlock\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1782\u001b[0m         \u001b[0mblocks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1783\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\kkang\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_simple_blockify\u001b[1;34m(tuples, dtype)\u001b[0m\n\u001b[0;32m   1824\u001b[0m     \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoerce\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m     \"\"\"\n\u001b[1;32m-> 1826\u001b[1;33m     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_stack_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1827\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1828\u001b[0m     \u001b[1;31m# TODO: CHECK DTYPE?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\kkang\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_stack_arrays\u001b[1;34m(tuples, dtype)\u001b[0m\n\u001b[0;32m   1872\u001b[0m     \u001b[0mstacked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1873\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1874\u001b[1;33m         \u001b[0mstacked\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_compat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1875\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1876\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mstacked\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (4650) into shape (4651)"
     ]
    }
   ],
   "source": [
    "def get_money_trend():\n",
    "    \n",
    "    url = 'http://finance.naver.com/sise/sise_deposit.nhn?&page='\n",
    "\n",
    "    source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "\n",
    "    last = source.find('td',class_='pgRR').find('a')['href']\n",
    "    last = last.split('&')[1]\n",
    "    last = last.split('=')[1]\n",
    "    last = int(last)\n",
    "\n",
    "    # 사용자의 PC내 폴더 주소를 입력하시면 됩니다.\n",
    "    path = 'd:\\\\moneytrend.xlsx'   \n",
    "    \n",
    "    # 날짜를 받을 리스트\n",
    "    date_list = []\n",
    "\n",
    "    # 값을 받을 사전\n",
    "    dictionary = {'고객예탁금': [],'신용잔고': [],'주식형 펀드': [],'혼합형 펀드': [],'채권형 펀드': []}\n",
    "\n",
    "    # dictionary key 인덱싱을 위한 리스트\n",
    "    name_list = ['고객예탁금','신용잔고','주식형 펀드','혼합형 펀드','채권형 펀드']\n",
    "\n",
    "\n",
    "    # count mask\n",
    "    mask = [1,3,5,7,9]\n",
    "    \n",
    "    for i in range(1,last+1):\n",
    "        \n",
    "        source = urlopen(url+ str(i)).read()\n",
    "        source = BeautifulSoup(source,'lxml')\n",
    "\n",
    "        #tbody = source.find('div',{'id':'wrap'}).find('div',{'class':'box_type_m'})\n",
    "        #trs = tbody.find_all('tr')\n",
    "\n",
    "        body = source.find('body')\n",
    "        trs = body.find_all('tr')\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.find_all('td',{'class':['date','rate_down','rate_up']})\n",
    "            count = 0\n",
    "    \n",
    "            for td in tds:\n",
    "                if count == 0:\n",
    "                    date_ = td.text.strip().replace('.','-')\n",
    "                    date_list.append(date_)\n",
    "                        \n",
    "                      \n",
    "                elif count in mask:\n",
    "                    temp = int((count-1)/2)\n",
    "                    dictionary[name_list[temp]].append(td.text.strip().replace(',',''))\n",
    "        \n",
    "                count += 1\n",
    "            if len(dictionary['고객예탁금']) != len(dictionary['채권형 펀드']):\n",
    "                print(str(i)+ '번째 페이지에서 누락된 값 발생')\n",
    "                print('누락된 데이터를 제거합니다')\n",
    "                    \n",
    "                date_list.pop(-1)\n",
    "                dictionary['고객예탁금'].pop(-1)\n",
    "                dictionary['신용잔고'].pop(-1)\n",
    "                dictionary['주식형 펀드'].pop(-1)\n",
    "                dictionary['혼합형 펀드'].pop(-1)\n",
    "                \n",
    "    # 개별 list 요소 갯수 파악 \n",
    "    #print(len(date_list))\n",
    "    #print(len(dictionary['고객예탁금']))\n",
    "    #print(len(dictionary['신용잔고']))\n",
    "    #print(len(dictionary['주식형 펀드']))\n",
    "    #print(len(dictionary['혼합형 펀드']))\n",
    "    #print(len(dictionary['채권형 펀드']))\n",
    "    print(str(i) + '번째 페이지 크롤링 완료')\n",
    "    df = pd.DataFrame(dictionary,index = date_list)\n",
    "    df = df.sort_index()\n",
    "    df.to_excel(path, encoding='utf-8')\n",
    "    print(df)\n",
    "\n",
    "\n",
    "get_money_trend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "날짜를 입력하세요 sample: '2019-01-10': 2021-03-31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>고객예탁금</th>\n",
       "      <th>신용잔고</th>\n",
       "      <th>주식형 펀드</th>\n",
       "      <th>혼합형 펀드</th>\n",
       "      <th>채권형 펀드</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21-04-01</th>\n",
       "      <td>657126</td>\n",
       "      <td>220929</td>\n",
       "      <td>808652</td>\n",
       "      <td>259814</td>\n",
       "      <td>1248581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           고객예탁금    신용잔고  주식형 펀드  혼합형 펀드   채권형 펀드\n",
       "21-04-01  657126  220929  808652  259814  1248581"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_money_trend_date():\n",
    "    url = 'http://finance.naver.com/sise/sise_deposit.nhn?&page='\n",
    "\n",
    "    source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "\n",
    "    last = source.find('td',class_='pgRR').find('a')['href']\n",
    "    last = last.split('&')[1]\n",
    "    last = last.split('=')[1]\n",
    "    last = int(last)\n",
    "\n",
    "    # 사용자의 PC내 폴더 주소를 입력하시면 됩니다.\n",
    "    path = 'd:\\\\money_trend.xlsx'\n",
    "\n",
    "    \n",
    "    until_date = input(\"날짜를 입력하세요 sample: '2019-01-10': \")\n",
    "    \n",
    "    year = until_date.split('-')[0]\n",
    "    mm = until_date.split('-')[1]\n",
    "    dd = until_date.split('-')[2]\n",
    "    year=year[2:]\n",
    "    until_date = year+'-'+mm+'-'+dd\n",
    "    \n",
    "    #df = DataFrame(columns = ['고객예탁금', '신용잔고','주식형 펀드','혼합형 펀드','채권형 펀드'])\n",
    "\n",
    "    # 날짜를 받을 리스트\n",
    "    date_list = []\n",
    "\n",
    "    \n",
    "    # 값을 받을 사전\n",
    "    dictionary = {'고객예탁금': [],\n",
    "                  '신용잔고': [],\n",
    "                  '주식형 펀드': [],\n",
    "                  '혼합형 펀드': [],\n",
    "                  '채권형 펀드': []\n",
    "                  }\n",
    "\n",
    "    # dictionary key 인덱싱을 위한 리스트\n",
    "    name_list = ['고객예탁금','신용잔고','주식형 펀드','혼합형 펀드','채권형 펀드']\n",
    "\n",
    "\n",
    "    # count mask\n",
    "    mask = [1,3,5,7,9]\n",
    "    \n",
    "    for i in range(1,last+1):\n",
    "        \n",
    "        source = urlopen(url+ str(i)).read()\n",
    "        source = BeautifulSoup(source,'lxml')\n",
    "\n",
    "        #tbody = source.find('div',{'id':'wrap'}).find('div',{'class':'box_type_m'})\n",
    "        #trs = tbody.find_all('tr')\n",
    "\n",
    "        body = source.find('body')\n",
    "        trs = body.find_all('tr')\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.find_all('td',{'class':['date','rate_down','rate_up']})\n",
    "            count = 0\n",
    "    \n",
    "            for td in tds:\n",
    "                if count == 0:\n",
    "                    date_ = td.text.strip().replace('.','-')\n",
    "                    if date_ <=  until_date :\n",
    "                    #if date_ <=  '19-03-05' :\n",
    "                        df = pd.DataFrame(dictionary,index = date_list)\n",
    "                        df = df.sort_index()\n",
    "                        df.to_excel(path, encoding='utf-8')\n",
    "                        return df\n",
    "                    date_list.append(date_)\n",
    "                    \n",
    "                elif count in mask:\n",
    "                    temp = int((count-1)/2)\n",
    "                    dictionary[name_list[temp]].append(td.text.strip().replace(',',''))\n",
    "                \n",
    "       \n",
    "                count += 1\n",
    "\n",
    "get_money_trend_date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KPI200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_kpi200():\n",
    "    \n",
    "    url = 'https://finance.naver.com/sise/sise_index_day.nhn?code=KPI200&page='\n",
    "\n",
    "    source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "\n",
    "    last = source.find('td',class_='pgRR').find('a')['href']\n",
    "    last = last.split('page')[1]\n",
    "    last = last.split('=')[1]\n",
    "    last = int(last)\n",
    "    print(last)\n",
    "\n",
    "    # 사용자의 PC내 폴더 주소를 입력하시면 됩니다.\n",
    "    path = 'd:\\\\kpi200.xlsx'\n",
    "    \n",
    "    # 날짜를 받을 리스트\n",
    "    date_list = []\n",
    "\n",
    "    # 값을 받을 사전\n",
    "    dictionary = {'KPI200': [],'거래량': []}\n",
    "\n",
    "    # dictionary key 인덱싱을 위한 리스트\n",
    "    name_list = ['KPI200','거래량']\n",
    "\n",
    "\n",
    "    # count mask\n",
    "    mask = [1,3]\n",
    "    \n",
    "    for i in range(1,last+1):\n",
    "        \n",
    "        source = urlopen(url+ str(i)).read()\n",
    "        source = BeautifulSoup(source,'lxml')\n",
    "\n",
    "        #tbody = source.find('div',{'id':'wrap'}).find('div',{'class':'box_type_m'})\n",
    "        #trs = tbody.find_all('tr')\n",
    "\n",
    "        body = source.find('body')\n",
    "        trs = body.find_all('tr')\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.find_all('td',{'class':['date','number_1']})\n",
    "            count = 0\n",
    "    \n",
    "            for td in tds:\n",
    "                if count == 0:\n",
    "                    date_ = td.text.strip().replace('.','-')\n",
    "                    date_list.append(date_)\n",
    "                        \n",
    "                      \n",
    "                elif count in mask:\n",
    "                    temp = int(count/3)\n",
    "                    dictionary[name_list[temp]].append(td.text.strip().replace(',',''))\n",
    "        \n",
    "                count += 1\n",
    "            if len(date_list) != len(dictionary['KPI200']):\n",
    "                print(str(i)+ '번째 페이지에서 누락된 값 발생')\n",
    "                print('누락된 데이터를 제거합니다')\n",
    "                    \n",
    "                date_list.pop(-1)\n",
    "                #dictionary['KPI200'].pop(-1)\n",
    "                dictionary['거래량'].pop(-1)\n",
    "                \n",
    "    # 개별 list 요소 갯수 파악 \n",
    "    #print(len(date_list))\n",
    "    #print(len(dictionary['개인']))\n",
    "    #print(len(dictionary['외국인']))\n",
    "    #print(len(dictionary['기관']))\n",
    "\n",
    "    print(str(i) + '번째 페이지 크롤링 완료')\n",
    "    df = pd.DataFrame(dictionary,index = date_list)\n",
    "    df = df.sort_index()\n",
    "    df.to_excel(path, encoding='utf-8')\n",
    "    print(df)\n",
    "\n",
    "get_kpi200()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_kpi200_date():\n",
    "    \n",
    "    url = 'https://finance.naver.com/sise/sise_index_day.nhn?code=KPI200&page='\n",
    "\n",
    "    source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "\n",
    "    last = source.find('td',class_='pgRR').find('a')['href']\n",
    "    last = last.split('page')[1]\n",
    "    last = last.split('=')[1]\n",
    "    last = int(last)\n",
    "    print(last)\n",
    "\n",
    "    # 사용자의 PC내 폴더 주소를 입력하시면 됩니다.\n",
    "    path = 'd:\\\\kpi200.xlsx'\n",
    "\n",
    "    until_date = input(\"날짜를 입력하세요 sample: '2019-01-10': \")\n",
    "    \n",
    "    year = until_date.split('-')[0]\n",
    "    mm = until_date.split('-')[1]\n",
    "    dd = until_date.split('-')[2]\n",
    "    #year=year[2:]\n",
    "    until_date = year+'-'+mm+'-'+dd\n",
    "    \n",
    "    # 날짜를 받을 리스트\n",
    "    date_list = []\n",
    "\n",
    "    # 값을 받을 사전\n",
    "    dictionary = {'KPI200': [],'거래량': []}\n",
    "\n",
    "    # dictionary key 인덱싱을 위한 리스트\n",
    "    name_list = ['KPI200','거래량']\n",
    "\n",
    "\n",
    "    # count mask\n",
    "    mask = [1,3]\n",
    "    \n",
    "    for i in range(1,last+1):\n",
    "        \n",
    "        source = urlopen(url+ str(i)).read()\n",
    "        source = BeautifulSoup(source,'lxml')\n",
    "\n",
    "        #tbody = source.find('div',{'id':'wrap'}).find('div',{'class':'box_type_m'})\n",
    "        #trs = tbody.find_all('tr')\n",
    "\n",
    "        body = source.find('body')\n",
    "        trs = body.find_all('tr')\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.find_all('td',{'class':['date','number_1']})\n",
    "            count = 0\n",
    "    \n",
    "            for td in tds:\n",
    "                if count == 0:\n",
    "                    date_ = td.text.strip().replace('.','-')\n",
    "                    if date_ <=  until_date :\n",
    "                    #if date_ <=  '19-03-05' :\n",
    "                        df = pd.DataFrame(dictionary,index = date_list)\n",
    "                        df = df.sort_index()\n",
    "                        df.to_excel(path, encoding='utf-8')\n",
    "                        return df   \n",
    "                    date_list.append(date_)\n",
    "                    #print(date_list)\n",
    "                elif count in mask:\n",
    "                    temp = int(count/3)\n",
    "                    dictionary[name_list[temp]].append(td.text.strip().replace(',',''))\n",
    "                    #print(dictionary[name_list[temp]])\n",
    "                count += 1\n",
    "                \n",
    "get_kpi200_date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investor Trend"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_investor_trend():\n",
    "    \n",
    "    url = 'http://finance.naver.com/sise/investorDealTrendDay.nhn?bizdate=2020601&sosok=&page='\n",
    "\n",
    "    source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "\n",
    "    last = source.find('td',class_='pgRR').find('a')['href']\n",
    "    last = last.split('page')[1]\n",
    "    last = last.split('=')[1]\n",
    "    last = int(last)\n",
    "    print(last)\n",
    "\n",
    "    # 사용자의 PC내 폴더 주소를 입력하시면 됩니다.\n",
    "    path = 'd:\\\\investortrend.xlsx'\n",
    "    \n",
    "    # 날짜를 받을 리스트\n",
    "    date_list = []\n",
    "\n",
    "    # 값을 받을 사전\n",
    "    dictionary = {'개인': [],'외국인': [],'기관': []}\n",
    "\n",
    "    # dictionary key 인덱싱을 위한 리스트\n",
    "    name_list = ['개인','외국인','기관']\n",
    "\n",
    "\n",
    "    # count mask\n",
    "    mask = [1,2,3]\n",
    "    \n",
    "    for i in range(1,last+1):\n",
    "        \n",
    "        source = urlopen(url+ str(i)).read()\n",
    "        source = BeautifulSoup(source,'lxml')\n",
    "\n",
    "        #tbody = source.find('div',{'id':'wrap'}).find('div',{'class':'box_type_m'})\n",
    "        #trs = tbody.find_all('tr')\n",
    "\n",
    "        body = source.find('body')\n",
    "        trs = body.find_all('tr')\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.find_all('td',{'class':['date2','rate_down3','rate_up3']})\n",
    "            count = 0\n",
    "    \n",
    "            for td in tds:\n",
    "                if count == 0:\n",
    "                    date_ = td.text.strip().replace('.','-')\n",
    "                    date_list.append(date_)\n",
    "                        \n",
    "                      \n",
    "                elif count in mask:\n",
    "                    temp = int(count-1)\n",
    "                    dictionary[name_list[temp]].append(td.text.strip().replace(',',''))\n",
    "        \n",
    "                count += 1\n",
    "            if len(date_list) != len(dictionary['개인']):\n",
    "                print(str(i)+ '번째 페이지에서 누락된 값 발생')\n",
    "                print('누락된 데이터를 제거합니다')\n",
    "                    \n",
    "                date_list.pop(-1)\n",
    "                dictionary['개인'].pop(-1)\n",
    "                dictionary['외국인'].pop(-1)\n",
    "                dictionary['기관'].pop(-1)\n",
    "                \n",
    "    # 개별 list 요소 갯수 파악 \n",
    "    #print(len(date_list))\n",
    "    #print(len(dictionary['개인']))\n",
    "    #print(len(dictionary['외국인']))\n",
    "    #print(len(dictionary['기관']))\n",
    "\n",
    "    print(str(i) + '번째 페이지 크롤링 완료')\n",
    "    df = pd.DataFrame(dictionary,index = date_list)\n",
    "    df = df.sort_index()\n",
    "    df.to_excel(path, encoding='utf-8')\n",
    "    print(df)\n",
    "\n",
    "get_investor_trend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396\n",
      "날짜를 입력하세요 sample: '2019-01-10': 2021-03-15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>개인</th>\n",
       "      <th>외국인</th>\n",
       "      <th>기관</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [개인, 외국인, 기관]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_investor_trend_date():\n",
    "    \n",
    "    url = 'http://finance.naver.com/sise/investorDealTrendDay.nhn?bizdate=2020601&sosok=&page='\n",
    "\n",
    "    source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "\n",
    "    last = source.find('td',class_='pgRR').find('a')['href']\n",
    "    last = last.split('page')[1]\n",
    "    last = last.split('=')[1]\n",
    "    last = int(last)\n",
    "    print(last)\n",
    "\n",
    "    # 사용자의 PC내 폴더 주소를 입력하시면 됩니다.\n",
    "    path = 'd:\\\\investortrend.xlsx'\n",
    "\n",
    "    until_date = input(\"날짜를 입력하세요 sample: '2019-01-10': \")\n",
    "    \n",
    "    year = until_date.split('-')[0]\n",
    "    mm = until_date.split('-')[1]\n",
    "    dd = until_date.split('-')[2]\n",
    "    year=year[2:]\n",
    "    until_date = year+'-'+mm+'-'+dd\n",
    "    \n",
    "    # 날짜를 받을 리스트\n",
    "    date_list = []\n",
    "\n",
    "    # 값을 받을 사전\n",
    "    dictionary = {'개인': [],'외국인': [],'기관': []}\n",
    "\n",
    "    # dictionary key 인덱싱을 위한 리스트\n",
    "    name_list = ['개인','외국인','기관']\n",
    "\n",
    "\n",
    "    # count mask\n",
    "    mask = [1,2,3]\n",
    "    \n",
    "    for i in range(1,last+1):\n",
    "        \n",
    "        source = urlopen(url+ str(i)).read()\n",
    "        source = BeautifulSoup(source,'lxml')\n",
    "\n",
    "        #tbody = source.find('div',{'id':'wrap'}).find('div',{'class':'box_type_m'})\n",
    "        #trs = tbody.find_all('tr')\n",
    "\n",
    "        body = source.find('body')\n",
    "        trs = body.find_all('tr')\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.find_all('td',{'class':['date2','rate_down3','rate_up3']})\n",
    "            count = 0\n",
    "    \n",
    "            for td in tds:\n",
    "                if count == 0:\n",
    "                    date_ = td.text.strip().replace('.','-')\n",
    "                    if date_ <=  until_date :\n",
    "                        df = pd.DataFrame(dictionary,index = date_list)\n",
    "                        df = df.sort_index()\n",
    "                        df.to_excel(path, encoding='utf-8')\n",
    "                        return df   \n",
    "                    date_list.append(date_)\n",
    "                    #print(date_list)\n",
    "                elif count in mask:\n",
    "                    temp = int(count-1)\n",
    "                    dictionary[name_list[temp]].append(td.text.strip().replace(',',''))\n",
    "                    \n",
    "                count += 1\n",
    "                \n",
    "get_investor_trend_date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Program Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_program_trend():\n",
    "    \n",
    "    url = 'https://finance.naver.com/sise/programDealTrendDay.nhn?bizdate=20200315&sosok=&page='\n",
    "\n",
    "    source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "\n",
    "    last = source.find('td',class_='pgRR').find('a')['href']\n",
    "    last = last.split('page')[1]\n",
    "    last = last.split('=')[1]\n",
    "    last = int(last)\n",
    "    print(last)\n",
    "\n",
    "    # 사용자의 PC내 폴더 주소를 입력하시면 됩니다.\n",
    "    path = 'd:\\\\programtrend.xlsx'\n",
    "    \n",
    "    # 날짜를 받을 리스트\n",
    "    date_list = []\n",
    "\n",
    "    # 값을 받을 사전\n",
    "    dictionary = {'차익': [],'비차익': [],'전체': []}\n",
    "\n",
    "    # dictionary key 인덱싱을 위한 리스트\n",
    "    name_list = ['차익','비차익','전체']\n",
    "\n",
    "\n",
    "    # count mask\n",
    "    mask = [3,6,9]\n",
    "    \n",
    "    for i in range(1,last+1):\n",
    "        \n",
    "        source = urlopen(url+ str(i)).read()\n",
    "        source = BeautifulSoup(source,'lxml')\n",
    "\n",
    "        #tbody = source.find('div',{'id':'wrap'}).find('div',{'class':'box_type_m'})\n",
    "        #trs = tbody.find_all('tr')\n",
    "\n",
    "        body = source.find('body')\n",
    "        trs = body.find_all('tr')\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.find_all('td',{'class':['date','rate_down','rate_up']})\n",
    "            count = 0\n",
    "    \n",
    "            for td in tds:\n",
    "                if count == 0:\n",
    "                    date_ = td.text.strip().replace('.','-')\n",
    "                    date_list.append(date_)\n",
    "                        \n",
    "                      \n",
    "                elif count in mask:\n",
    "                    temp = int((count/3)-1)\n",
    "                    dictionary[name_list[temp]].append(td.text.strip().replace(',',''))\n",
    "        \n",
    "                count += 1\n",
    "            if len(date_list) != len(dictionary['전체']):\n",
    "                print(str(i)+ '번째 페이지에서 누락된 값 발생')\n",
    "                print('누락된 데이터를 제거합니다')\n",
    "                    \n",
    "                date_list.pop(-1)\n",
    "                dictionary['차익'].pop(-1)\n",
    "                dictionary['비차익'].pop(-1)\n",
    "                #dictionary['전체'].pop(-1)\n",
    "                \n",
    "    # 개별 list 요소 갯수 파악 \n",
    "    print(len(date_list))\n",
    "    print(len(dictionary['차익']))\n",
    "    print(len(dictionary['비차익']))\n",
    "    print(len(dictionary['전체']))\n",
    "\n",
    "    print(str(i) + '번째 페이지 크롤링 완료')\n",
    "    df = pd.DataFrame(dictionary,index = date_list)\n",
    "    df = df.sort_index()\n",
    "    df.to_excel(path, encoding='utf-8')\n",
    "    print(df)\n",
    "\n",
    "get_program_trend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376\n",
      "날짜를 입력하세요 sample: '2019-01-10': 2021-02-01\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>차익</th>\n",
       "      <th>비차익</th>\n",
       "      <th>전체</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [차익, 비차익, 전체]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_program_trend_date():\n",
    "    \n",
    "    url = 'https://finance.naver.com/sise/programDealTrendDay.nhn?bizdate=20200315&sosok=&page='\n",
    "\n",
    "    source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "\n",
    "    last = source.find('td',class_='pgRR').find('a')['href']\n",
    "    last = last.split('page')[1]\n",
    "    last = last.split('=')[1]\n",
    "    last = int(last)\n",
    "    print(last)\n",
    "\n",
    "    # 사용자의 PC내 폴더 주소를 입력하시면 됩니다.\n",
    "    path = 'd:\\\\programtrend.xlsx'\n",
    "\n",
    "    until_date = input(\"날짜를 입력하세요 sample: '2019-01-10': \")\n",
    "    \n",
    "    year = until_date.split('-')[0]\n",
    "    mm = until_date.split('-')[1]\n",
    "    dd = until_date.split('-')[2]\n",
    "    year=year[2:]\n",
    "    until_date = year+'-'+mm+'-'+dd\n",
    "    \n",
    "    # 날짜를 받을 리스트\n",
    "    date_list = []\n",
    "\n",
    "    # 값을 받을 사전\n",
    "    dictionary = {'차익': [],'비차익': [],'전체': []}\n",
    "\n",
    "    # dictionary key 인덱싱을 위한 리스트\n",
    "    name_list = ['차익','비차익','전체']\n",
    "\n",
    "\n",
    "    # count mask\n",
    "    mask = [3,6,9]\n",
    "    \n",
    "    for i in range(1,last+1):\n",
    "        \n",
    "        source = urlopen(url+ str(i)).read()\n",
    "        source = BeautifulSoup(source,'lxml')\n",
    "\n",
    "        #tbody = source.find('div',{'id':'wrap'}).find('div',{'class':'box_type_m'})\n",
    "        #trs = tbody.find_all('tr')\n",
    "\n",
    "        body = source.find('body')\n",
    "        trs = body.find_all('tr')\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.find_all('td',{'class':['date','rate_down','rate_up']})\n",
    "            count = 0\n",
    "    \n",
    "            for td in tds:\n",
    "                if count == 0:\n",
    "                    date_ = td.text.strip().replace('.','-')\n",
    "                    if date_ <=  until_date :\n",
    "                        df = pd.DataFrame(dictionary,index = date_list)\n",
    "                        df = df.sort_index()\n",
    "                        df.to_excel(path, encoding='utf-8')\n",
    "                        return df   \n",
    "                    date_list.append(date_)\n",
    "                    #print(date_list)\n",
    "                elif count in mask:\n",
    "                    temp = int((count/3)-1)\n",
    "                    dictionary[name_list[temp]].append(td.text.strip().replace(',',''))\n",
    "                    \n",
    "                count += 1\n",
    "get_program_trend_date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 선물"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def  futures():\n",
    "    \n",
    "    url = 'https://finance.naver.com/sise/sise_index_day.nhn?code=FUT&page='\n",
    "\n",
    "    source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "\n",
    "    last = source.find('td',class_='pgRR').find('a')['href']\n",
    "    last = last.split('page')[1]\n",
    "    last = last.split('=')[1]\n",
    "    last = int(last)\n",
    "    print(last)\n",
    "\n",
    "    # 사용자의 PC내 폴더 주소를 입력하시면 됩니다.\n",
    "    path = 'd:\\\\futures.xlsx'\n",
    "    \n",
    "    # 날짜를 받을 리스트\n",
    "    date_list = []\n",
    "\n",
    "    # 값을 받을 사전\n",
    "    dictionary = {'Close': [],'updown': [],'rate': []}\n",
    "\n",
    "    # dictionary key 인덱싱을 위한 리스트\n",
    "    name_list = ['Close','updown','rate']\n",
    "\n",
    "\n",
    "    # count mask\n",
    "    mask = [1,2,3]\n",
    "    \n",
    "    for i in range(1,last+1):\n",
    "        \n",
    "        source = urlopen(url+ str(i)).read()\n",
    "        source = BeautifulSoup(source,'lxml')\n",
    "\n",
    "        #tbody = source.find('div',{'id':'wrap'}).find('div',{'class':'box_type_m'})\n",
    "        #trs = tbody.find_all('tr')\n",
    "\n",
    "        body = source.find('body')\n",
    "        trs = body.find_all('tr')\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.find_all('td',{'class':['date','number_1','rate_down']})\n",
    "            count = 0\n",
    "    \n",
    "            for td in tds:\n",
    "                if count == 0:\n",
    "                    date_ = td.text.strip().replace('.','-')\n",
    "                    date_list.append(date_)\n",
    "                        \n",
    "                      \n",
    "                elif count in mask:\n",
    "                    temp = int(count-1)\n",
    "                    dictionary[name_list[temp]].append(td.text.strip().replace(',',''))\n",
    "        \n",
    "                count += 1\n",
    "            if len(date_list) != len(dictionary['Close']):\n",
    "                print(str(i)+ '번째 페이지에서 누락된 값 발생')\n",
    "                print('누락된 데이터를 제거합니다')\n",
    "                    \n",
    "                date_list.pop(-1)\n",
    "                dictionary['Close'].pop(-1)\n",
    "                dictionary['updown'].pop(-1)\n",
    "                dictionary['rate'].pop(-1)\n",
    "                \n",
    "    # 개별 list 요소 갯수 파악 \n",
    "    #print(len(date_list))\n",
    "    #print(len(dictionary['개인']))\n",
    "    #print(len(dictionary['외국인']))\n",
    "    #print(len(dictionary['기관']))\n",
    "\n",
    "    print(str(i) + '번째 페이지 크롤링 완료')\n",
    "    df = pd.DataFrame(dictionary,index = date_list)\n",
    "    df = df.sort_index()\n",
    "    df.to_excel(path, encoding='utf-8')\n",
    "    print(df)\n",
    "    \n",
    "futures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 관리종목"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Name\n",
      "Date                 \n",
      "2020-08-01         한프\n",
      "2020-08-01     더블유에프엠\n",
      "2020-08-01      솔고바이오\n",
      "2020-08-01      뉴프라이드\n",
      "2020-08-01  에스모 머티리얼즈\n",
      "...               ...\n",
      "2020-08-01       하이소닉\n",
      "2020-08-01      씨엔플러스\n",
      "2020-08-01      파티게임즈\n",
      "2020-08-01        감마누\n",
      "2020-08-01     한국정밀기계\n",
      "\n",
      "[107 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "from  datetime import datetime\n",
    "import pandas as pd\n",
    "import xlsxwriter\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlalchemy \n",
    "import pymysql\n",
    "\n",
    "today = datetime.now()\n",
    "today = today.strftime(\"%Y-%m-%d\")\n",
    "#today=input('입력')\n",
    "url = 'https://finance.naver.com/sise/management.nhn'\n",
    "source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "data = []\n",
    "\n",
    "path = 'f:\\\\stockdata\\\\관리종목\\\\'+today+'.xlsx'\n",
    "body = source.find('body')\n",
    "trs = body.find_all('tr')\n",
    "name = []\n",
    "for tr in trs:\n",
    "    tds = tr.find_all('a',{'class':\"tltle\"})\n",
    "    for td in tds:\n",
    "        name.append(td.text.strip())\n",
    "\n",
    "df = pd.DataFrame(name)\n",
    "df['Date']=str(today)\n",
    "df = df.set_index('Date')\n",
    "df.columns=['Name']\n",
    "df.to_excel(path)\n",
    "\n",
    "now = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "conn = pymysql.connect(host = 'localhost', user = 'kkang', password = 'leaf2027' ,db = 'stock')\n",
    "curs = conn.cursor()\n",
    "\n",
    "df = pd.read_excel(path)\n",
    "df.to_sql(name='badstock', con=engine, if_exists='append', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime as dt\n",
    "from datetime import datetime,timedelta\n",
    "from urllib.request import urlopen\n",
    "import sqlalchemy \n",
    "import pymysql\n",
    "import talib.abstract as ta\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "now = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "engine = sqlalchemy.create_engine('mysql+pymysql://kkang:leaf2027@localhost/stock?charset=utf8',encoding='utf-8')\n",
    "conn = pymysql.connect(host = 'localhost', user = 'kkang', password = 'leaf2027' ,db = 'stock')\n",
    "curs = conn.cursor()\n",
    "path = 'f:\\\\stockdata\\\\관리종목\\\\'+today+'.xlsx'\n",
    "df = pd.read_excel(path)\n",
    "df.to_sql(name='badstock', con=engine, if_exists='append', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_program_trend():\n",
    "    \n",
    "    url = 'https://finance.naver.com/sise/management.nhn'\n",
    "\n",
    "    source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "\n",
    "    body = source.find('body')\n",
    "    trs = body.find_all('tr')\n",
    "    #print(trs)\n",
    "    \n",
    "    name_list = []\n",
    "    \n",
    "    for tr in trs:\n",
    "        tds = tr.find_all('td')\n",
    "        for a in tds:\n",
    "            #title = a.find_all('a',{'href':\"/item/main.nhn\"})\n",
    "            title = a.find_all('a',{'class':\"tltle\"})\n",
    "            #title = a.find_all('a')\n",
    "            name_ = title.text.strip().replace('.','')\n",
    "            #df = pd.DataFrame(dictionary,index = date_list)\n",
    "            print(name_)\n",
    "        #print(tds)\n",
    "\n",
    "get_program_trend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_program_trend():\n",
    "    \n",
    "    url = 'https://finance.naver.com/sise/management.nhn'\n",
    "\n",
    "    source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "\n",
    "    body = source.find('body')\n",
    "    trs = body.find_all('tr')\n",
    "    #print(trs)\n",
    "    \n",
    "    name = []\n",
    "    \n",
    "    for tr in trs:\n",
    "        tds = tr.find_all('td')\n",
    "        #print(tds)\n",
    "        for td in tds:\n",
    "            td = td.find_all('a',{'class':\"tltle\"})\n",
    "            name.append(td)\n",
    "            #title = a.find_all('a',{'href':\"/item/main.nhn\"})\n",
    "            #tltle = a.find_all('a',{'class':\"tltle\"})\n",
    "            #title = a.find_all('a')\n",
    "            #name = tltle.text\n",
    "            #df = pd.DataFrame(dictionary,index = date_list)\n",
    "            #print(name)\n",
    "            #print(td)\n",
    "        print(name)\n",
    "\n",
    "get_program_trend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from  datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "today = datetime.now()\n",
    "today = today.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "#url = 'http://finance.naver.com/sise/investorDealTrendDay.nhn?bizdate=2020601&sosok=&page=1'\n",
    "url = 'https://finance.naver.com/sise/management.nhn'\n",
    "source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "data = []\n",
    "\n",
    "path = 'd:\\\\stockdata\\\\관리종목\\\\'+today+'.xlsx'\n",
    "body = source.find('body')\n",
    "trs = body.find_all('tr')\n",
    "name = []\n",
    "for tr in trs:\n",
    "    #tds = tr.find_all('td',{'class':['date2','rate_down3','rate_up3']})\n",
    "    tds = tr.find_all('a',{'class':\"tltle\"})\n",
    "    for td in tds:\n",
    "        name.append(td.text.strip())\n",
    "\n",
    "df = pd.DataFrame(name,columns=['관리종목'])\n",
    "df['Date']=today\n",
    "df = df.set_index('Date')\n",
    "df.to_excel(path)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "today = datetime.now()\n",
    "today = today.strftime(\"%Y-%m-%d\")\n",
    "print(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_investor_trend_date():\n",
    "    \n",
    "    url = 'http://finance.naver.com/sise/investorDealTrendDay.nhn?bizdate=2020601&sosok=&page='\n",
    "\n",
    "    source = urlopen(url).read()   # 지정한 페이지에서 코드 읽기\n",
    "    source = BeautifulSoup(source, 'lxml')   # 뷰티풀 스프로 태그별로 코드 분류\n",
    "\n",
    "    last = source.find('td',class_='pgRR').find('a')['href']\n",
    "    last = last.split('page')[1]\n",
    "    last = last.split('=')[1]\n",
    "    last = int(last)\n",
    "    print(last)\n",
    "\n",
    "    # 사용자의 PC내 폴더 주소를 입력하시면 됩니다.\n",
    "    path = 'd:\\\\investortrend.xlsx'\n",
    "\n",
    "    until_date = input(\"날짜를 입력하세요 sample: '2019-01-10': \")\n",
    "    \n",
    "    year = until_date.split('-')[0]\n",
    "    mm = until_date.split('-')[1]\n",
    "    dd = until_date.split('-')[2]\n",
    "    year=year[2:]\n",
    "    until_date = year+'-'+mm+'-'+dd\n",
    "    \n",
    "    # 날짜를 받을 리스트\n",
    "    date_list = []\n",
    "\n",
    "    # 값을 받을 사전\n",
    "    dictionary = {'개인': [],'외국인': [],'기관': []}\n",
    "\n",
    "    # dictionary key 인덱싱을 위한 리스트\n",
    "    name_list = ['개인','외국인','기관']\n",
    "\n",
    "\n",
    "    # count mask\n",
    "    mask = [1,2,3]\n",
    "    \n",
    "    for i in range(1,last+1):\n",
    "        \n",
    "        source = urlopen(url+ str(i)).read()\n",
    "        source = BeautifulSoup(source,'lxml')\n",
    "\n",
    "        #tbody = source.find('div',{'id':'wrap'}).find('div',{'class':'box_type_m'})\n",
    "        #trs = tbody.find_all('tr')\n",
    "\n",
    "        body = source.find('body')\n",
    "        trs = body.find_all('tr')\n",
    "\n",
    "        for tr in trs:\n",
    "            tds = tr.find_all('td',{'class':['date2','rate_down3','rate_up3']})\n",
    "            print(tds)\n",
    "            #for td in tds:\n",
    "                #print(td.fide_all('td',{'class':'date2'}))\n",
    "                #print(td.text.strip())\n",
    "get_investor_trend_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_investor_trend_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
